{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgzZWi_cXqBI",
        "outputId": "6cdc7950-81e3-4d73-ecbe-a9da4be93a43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBXN0lsHcJ6G",
        "outputId": "d2a57a76-3ca5-4fed-b3e6-595aee94454c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "gh is already the newest version (2.4.0+dfsg1-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "! apt -y install gh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL-gwpCxaHn3",
        "outputId": "e108fad5-2a4f-4d45-8819-2c4a71e1a0ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'M-IFEval' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/lightblue-tech/M-IFEval.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2mHsnuRjn5I",
        "outputId": "ec8b5af7-4a40-46b7-e716-f19203e9afe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "! huggingface-cli login --token {userdata.get('HF_TOKEN')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "a7SInk5O2Zl-"
      },
      "outputs": [],
      "source": [
        "! cd M-IFEval && pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Local inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install -q vllm bitsandbytes hf-transfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNyBbCTa_LQ2",
        "outputId": "697291a9-01d9-46b3-c5e5-1c87548663f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5tutI3e-4wA",
        "outputId": "73e2eb5e-3021-453b-9b08-338b007c9576"
      },
      "outputs": [],
      "source": [
        "local_model_names = ['CohereForAI/c4ai-command-r-plus-4bit',\n",
        " 'CohereForAI/c4ai-command-r-v01-4bit',\n",
        " 'CohereForAI/aya-23-8B',\n",
        " 'Qwen/Qwen2.5-0.5B-Instruct-GPTQ-Int4',\n",
        " 'Qwen/Qwen2.5-1.5B-Instruct-GPTQ-Int4',\n",
        " 'Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4',\n",
        " 'Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4',\n",
        " 'Qwen/Qwen2.5-14B-Instruct-GPTQ-Int4',\n",
        " 'Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4',\n",
        " 'Qwen/Qwen2.5-72B-Instruct-GPTQ-Int4',\n",
        " 'hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4',\n",
        " 'hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4',\n",
        " 'mistralai/Mistral-7B-Instruct-v0.3']\n",
        "\n",
        "for local_model_name in local_model_names:\n",
        "    ! cd M-IFEval && HF_HUB_ENABLE_HF_TRANSFER=1 python get_responses.py --model_name {local_model_name}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Remote inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSATCeaB_Na4"
      },
      "outputs": [],
      "source": [
        "! pip install -q anthropic openai google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xn4NZ6_d_Nc9"
      },
      "outputs": [],
      "source": [
        "local_model_names = ['gpt-4o-mini-2024-07-18',\n",
        " 'gpt-4o-2024-08-06',\n",
        " 'o1-preview-2024-09-12',\n",
        " 'o1-mini-2024-09-12',\n",
        " 'claude-3-haiku-20240307',\n",
        " 'claude-3-5-sonnet-20240620',\n",
        " 'claude-3-opus-20240229',\n",
        " 'gemini-1.5-pro-002',\n",
        " 'gemini-1.5-flash-002']\n",
        "\n",
        "for local_model_name in local_model_names:\n",
        "    ! cd M-IFEval && python get_responses.py --model_name {local_model_name}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjerXUbP_Ne2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmwfE-eZ_Ng3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meoJg0NG_Niv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iThFcLyE_Nnt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
